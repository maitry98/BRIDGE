{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e920c-1170-4fe2-94ab-14882f0d443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score, normalized_mutual_info_score,\n",
    "    adjusted_mutual_info_score, fowlkes_mallows_score,\n",
    "    mutual_info_score, rand_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8663e95-dbb3-4660-9315-231c62261769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load config\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "selected_ds = config['selected_dataset']\n",
    "#selected_ds = \"Baron_Human\"\n",
    "ds_params = config[\"datasets\"][selected_ds][\"parameters\"]\n",
    "\n",
    "# Extract Dataset Specifics\n",
    "ds_config = config[\"datasets\"][selected_ds]\n",
    "data_path = ds_config[\"path\"]\n",
    "params = ds_config[\"parameters\"]\n",
    "\n",
    "# Map to variables used in your existing loop\n",
    "target_zero_percentages = params[\"target_percentage\"]\n",
    "seeds_per_rate = ds_params[\"seeds_per_rate\"]\n",
    "seeds_per_rate = {float(k): v for k, v in seeds_per_rate.items()}\n",
    "N_HVG = params[\"N_HVG\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "model_dir = Path(config[\"model_dir\"])\n",
    "bridge_iters = params[\"iter\"]\n",
    "\n",
    "print(f\"Ready to process {selected_ds} with {N_HVG} HVGs and seeds {seeds_per_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533003b1-fe07-45ca-b986-ac1bbc6fec03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert \\\n",
    "  --execute \\\n",
    "  --to notebook \\\n",
    "  \"scGPT Embeddings generation.ipynb\" \\\n",
    "  --output \"scGPT_Embeddings_executed.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f74b0d-944c-4f2f-9058-21dc63aa0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b24b64-6ce9-4d42-b0bb-adab513a1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_fast(X, k, b, gcn_norm, sym):\n",
    "    device = X.device\n",
    "    X = F.normalize(X, dim=1, p=2)\n",
    "    index = 0\n",
    "    values = torch.zeros(X.shape[0] * (k + 1)).to(device)\n",
    "    rows = torch.zeros(X.shape[0] * (k + 1)).to(device)\n",
    "    cols = torch.zeros(X.shape[0] * (k + 1)).to(device)\n",
    "\n",
    "    while index < X.shape[0]:\n",
    "        end = min(index + b, X.shape[0])\n",
    "        sub_tensor = X[index:end]\n",
    "        similarities = torch.mm(sub_tensor, X.t())\n",
    "        vals, inds = similarities.topk(k=k + 1, dim=-1)\n",
    "        values[index * (k + 1):(end) * (k + 1)] = vals.view(-1)\n",
    "        cols[index * (k + 1):(end) * (k + 1)] = inds.view(-1)\n",
    "        rows[index * (k + 1):(end) * (k + 1)] = torch.arange(index, end).view(-1, 1).repeat(1, k + 1).view(-1)\n",
    "        index += b\n",
    "\n",
    "    rows, cols = rows.long(), cols.long()\n",
    "    sparse_adj = SparseTensor(row=rows, col=cols, value=values).to(device)\n",
    "    return sparse_post_processing(sparse_adj, gcn_norm=gcn_norm, sym=sym).to_torch_sparse_coo_tensor().float()\n",
    "\n",
    "def sparse_post_processing(adj, add_self_loop=True, sym=True, gcn_norm=False):\n",
    "    from torch_sparse import fill_diag, sum as sparsesum, mul\n",
    "    if add_self_loop:\n",
    "        adj = fill_diag(adj, 2)\n",
    "    if sym:\n",
    "        adj = adj + adj.t()\n",
    "        adj = mul(adj, (torch.ones(adj.size(0), device=adj.device()) * 1/2).view(-1, 1))\n",
    "    deg = sparsesum(adj, dim=1)\n",
    "    if gcn_norm:\n",
    "        deg_inv_sqrt = deg.pow_(-0.5).masked_fill(deg == float('inf'), 0.)\n",
    "        adj = mul(adj, deg_inv_sqrt.view(-1, 1))\n",
    "        adj = mul(adj, deg_inv_sqrt.view(1, -1))\n",
    "    else:\n",
    "        deg_inv = deg.pow_(-1).masked_fill(deg == float('inf'), 0.)\n",
    "        adj = mul(adj, deg_inv.view(-1, 1))\n",
    "    return adj\n",
    "\n",
    "def drop_data(data_t, rate):\n",
    "    X = data_t.X\n",
    "    if scipy.sparse.issparse(X):\n",
    "        X = np.array(X.todense())\n",
    "    X_train = np.copy(X)\n",
    "    if rate > 0.0:\n",
    "        i, j = np.nonzero(X)\n",
    "        ix = np.random.choice(len(i), int(np.floor(rate * len(i))), replace=False)\n",
    "        X_train[i[ix], j[ix]] = 0.0\n",
    "    data_t.obsm['train'] = X_train\n",
    "    data_t.obsm['test'] = X\n",
    "    return data_t\n",
    "\n",
    "def forward(x, sparse_adj, mask, iters):\n",
    "    original_x = copy.copy(x)\n",
    "    device = sparse_adj.device\n",
    "    x = x.to(device)\n",
    "    for _ in tqdm(range(iters)):\n",
    "        x = torch.sparse.mm(sparse_adj, x)\n",
    "        if mask:\n",
    "            nonzero_idx = torch.nonzero(original_x)\n",
    "            x[nonzero_idx[:, 0], nonzero_idx[:, 1]] = original_x[nonzero_idx[:, 0], nonzero_idx[:, 1]]\n",
    "    return x.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ea0ce-6bd3-47ba-92c3-a5a27b160137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_method(method, adata, rate, seed, target_zero_percentage, adj_matrix=None,iters=None):\n",
    "    np.random.seed(seed)\n",
    "    #Prepare data and simulate dropout\n",
    "    adata_copy = adata.copy()\n",
    "    adata_copy = drop_data(adata_copy, rate)\n",
    "    filtered_matrix = torch.tensor(adata_copy.obsm[\"train\"], dtype=torch.float32)\n",
    "    ft = filtered_matrix.T\n",
    "    actual_zero_percentage = (filtered_matrix == 0).sum().item() / filtered_matrix.numel()\n",
    "    print(f\"Actual zero percentage: {actual_zero_percentage*100:.2f}%\")\n",
    "\n",
    "    #Run BRIDGE\n",
    "    if method == \"BRIDGE\":\n",
    "        ft = filtered_matrix\n",
    "        denoised = forward(ft, adj_matrix, iters=iters, mask=False)     \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    # Clustering Evaluation\n",
    "    celltype = adata.obs[\"celltype\"].values\n",
    "    kmeans = KMeans(n_clusters=np.unique(celltype).shape[0], n_init=20, random_state=0)\n",
    "    pred = kmeans.fit_predict(denoised.numpy())\n",
    "    true = celltype\n",
    "    #Compile Results\n",
    "    return {\n",
    "        \"method\": method,\n",
    "        \"target_zero_percentage\": target_zero_percentage,\n",
    "        \"dropout_rate\": rate,\n",
    "        \"random_seed\": seed,\n",
    "        \"actual_zero_percentage\": actual_zero_percentage,\n",
    "        \"RI\": rand_score(pred, true),\n",
    "        \"NMI\": normalized_mutual_info_score(pred, true),\n",
    "        \"AMI\": adjusted_mutual_info_score(pred, true),\n",
    "        \"FMI\": fowlkes_mallows_score(pred, true),\n",
    "        \"MI\": mutual_info_score(pred, true),\n",
    "        \"ARI\": adjusted_rand_score(pred, true),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a81e4-5c51-4b6c-a09e-a723602e15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for all metrics\n",
    "metrics_dict = {metric: [] for metric in ['RI', 'NMI', 'AMI', 'FMI', 'MI', 'ARI']}\n",
    "\n",
    "original_X = adata.X.toarray() if scipy.sparse.issparse(adata.X) else adata.X\n",
    "initial_zero_rate = (original_X == 0).sum() / original_X.size\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for target_zero_percentage in target_zero_percentages:\n",
    "    # Calculate required dropout rate to reach target sparsity\n",
    "    if target_zero_percentage > initial_zero_rate:\n",
    "        random_seeds = seeds_per_rate.get(target_zero_percentage, [0])\n",
    "        needed_zeros = int(target_zero_percentage * original_X.size)\n",
    "        needed_drops = needed_zeros - (original_X == 0).sum()\n",
    "        rate = max(0.0, min(1.0, needed_drops / np.count_nonzero(original_X)))\n",
    "    else:\n",
    "        rate = 0.0\n",
    "        random_seeds = [0]\n",
    "\n",
    "    # Iterating through seeds (currently fixed at 0)\n",
    "    for seed in random_seeds:\n",
    "        print(f\"Running for target_zero={target_zero_percentage:.2f}, seed={seed}\")\n",
    "        targetpercentage_100 = int(target_zero_percentage * 100)\n",
    "        # Load precomputed scGPT embeddings\n",
    "        file_name = f'Embeddings/{selected_ds}_Embeddings_{targetpercentage_100}_{seed}.h5ad'\n",
    "        embd = sc.read(file_name)\n",
    "        X_np = embd.obsm['X_scGPT']\n",
    "        X_torch = torch.tensor(X_np, dtype=torch.float32).to(device)\n",
    "        # Generate adjacency matrix\n",
    "        adj_matrix = knn_fast(X_torch, k=10, b=1000, gcn_norm=False, sym=True)\n",
    "        # Execute the method and store results\n",
    "        results_BRIDGE = run_method('BRIDGE', adata, rate, seed, target_zero_percentage, adj_matrix, bridge_iters)                 \n",
    "        for metric in metrics_dict:\n",
    "            metrics_dict[metric].append({\n",
    "                'target_zero_percentage': target_zero_percentage,\n",
    "                'dropout_rate': rate,\n",
    "                'random_seed': seed,\n",
    "                'actual_zero_percentage': results_BRIDGE['actual_zero_percentage'],\n",
    "                'BRIDGE': results_BRIDGE[metric],\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b167d-d644-4f54-ba67-212d91017762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to CSV\n",
    "for metric, data in metrics_dict.items():\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f'{metric}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
